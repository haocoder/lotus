# sem_cluster_by æ€§èƒ½åˆ†æä¸ä¼˜åŒ–æ–¹æ¡ˆ

## ğŸ“Š å½“å‰å®ç°åˆ†æ

### 1. æ¶æ„æ¦‚è§ˆ
```
sem_cluster_by (pandas accessor)
  â””â”€> lotus.utils.cluster() 
       â”œâ”€> GPUè·¯å¾„: lotus.utils.gpu_clustering.gpu_cluster()
       â””â”€> CPUè·¯å¾„: faiss.Kmeans (ç›´æ¥è°ƒç”¨)
```

### 2. è¯†åˆ«çš„æ€§èƒ½ç“¶é¢ˆ

#### ğŸ”´ å…³é”®æ€§èƒ½é—®é¢˜

1. **å‘é‡æ£€ç´¢æ•ˆç‡ä½ä¸‹**
   - å½“å‰: æ¯æ¬¡è°ƒç”¨éƒ½ä½¿ç”¨ `vs.get_vectors_from_index()` é€ä¸ªæå–å‘é‡
   - é—®é¢˜: å¯¹äºå¤§æ•°æ®é›†ï¼Œè¿™æ˜¯I/Oå¯†é›†å‹æ“ä½œ
   - å½±å“: O(n) çš„ç£ç›˜I/Oæ“ä½œ

2. **ç¼ºä¹æ‰¹å¤„ç†æ”¯æŒ**
   - å½“å‰: ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰æ•°æ®
   - é—®é¢˜: å¯¹äºè¶…å¤§æ•°æ®é›†(>100ä¸‡æ¡)ä¼šå¯¼è‡´å†…å­˜æº¢å‡º
   - ç¼ºå¤±: æ²¡æœ‰è‡ªé€‚åº”æ‰¹å¤„ç†ç­–ç•¥

3. **GPUä¼˜åŒ–ä¸å®Œæ•´**
   - å½“å‰: GPUä»…ç”¨äºK-meansè®¡ç®—
   - é—®é¢˜: å‘é‡è·å–å’Œé¢„å¤„ç†ä»åœ¨CPUè¿›è¡Œ
   - æŸå¤±: å¤§é‡CPU-GPUæ•°æ®ä¼ è¾“å¼€é”€

4. **ç¼ºå°‘ç¼“å­˜æœºåˆ¶**
   - å½“å‰: `@operator_cache` åªç¼“å­˜æœ€ç»ˆç»“æœ
   - é—®é¢˜: ä¸­é—´å‘é‡æ•°æ®ä¸è¢«ç¼“å­˜
   - å½±å“: é‡å¤æŸ¥è¯¢ç›¸åŒåˆ—ä¼šé‡æ–°åŠ è½½å‘é‡

5. **è¿”å›å€¼è®¾è®¡ä¸å®Œæ•´**
   - å½“å‰: æ³¨é‡Šæ‰äº† `return_scores` å’Œ `return_centroids` åŠŸèƒ½
   - é—®é¢˜: æ— æ³•è·å–ç°‡è´¨é‡è¯„ä¼°ä¿¡æ¯
   - é™åˆ¶: éš¾ä»¥è¯„ä¼°èšç±»æ•ˆæœ

#### ğŸŸ¡ æ¬¡è¦æ€§èƒ½é—®é¢˜

6. **ç¼ºä¹è¿›åº¦åé¦ˆ**
   - å¯¹äºé•¿æ—¶é—´è¿è¡Œçš„èšç±»ä»»åŠ¡ï¼Œæ²¡æœ‰è¿›åº¦æ¡

7. **é”™è¯¯å¤„ç†ä¸è¶³**
   - GPUå¤±è´¥å›é€€æ—¶å¯èƒ½ä¸¢å¤±è¯¦ç»†é”™è¯¯ä¿¡æ¯

8. **å‚æ•°éªŒè¯æ»å**
   - å‚æ•°éªŒè¯å‘ç”Ÿåœ¨å®é™…è®¡ç®—æ—¶ï¼Œä¸æ˜¯åˆå§‹é˜¶æ®µ

## ğŸ¯ ä¼˜åŒ–ç­–ç•¥

### Phase 1: æ ¸å¿ƒæ€§èƒ½ä¼˜åŒ– (é«˜ä¼˜å…ˆçº§)

#### 1.1 å‘é‡æ‰¹é‡è·å–ä¼˜åŒ–
```python
def _get_vectors_batch(vs, col_index_dir, ids, batch_size=10000):
    """æ‰¹é‡è·å–å‘é‡ï¼Œå‡å°‘I/Oæ¬¡æ•°"""
    if len(ids) <= batch_size:
        return vs.get_vectors_from_index(col_index_dir, ids)
    
    vectors = []
    for i in range(0, len(ids), batch_size):
        batch_ids = ids[i:i + batch_size]
        batch_vectors = vs.get_vectors_from_index(col_index_dir, batch_ids)
        vectors.append(batch_vectors)
    
    return np.vstack(vectors)
```

#### 1.2 è‡ªé€‚åº”æ‰¹å¤„ç†ç­–ç•¥
```python
def _adaptive_batch_size(n_samples, dim, use_gpu=False):
    """æ ¹æ®æ•°æ®è§„æ¨¡å’Œç¡¬ä»¶è‡ªé€‚åº”ç¡®å®šæ‰¹å¤§å°"""
    if use_gpu:
        try:
            import torch
            gpu_memory = torch.cuda.get_device_properties(0).total_memory
            # ä¿ç•™30%å†…å­˜ç”¨äºå…¶ä»–æ“ä½œ
            usable_memory = gpu_memory * 0.7
            # è€ƒè™‘å‘é‡å­˜å‚¨ + K-meansä¸­é—´ç»“æœ
            bytes_per_sample = dim * 4 * 3  # float32 * 3å€å®‰å…¨ç³»æ•°
            return min(n_samples, int(usable_memory / bytes_per_sample))
        except:
            return min(n_samples, 100000)
    else:
        import psutil
        available_ram = psutil.virtual_memory().available
        usable_ram = available_ram * 0.5
        bytes_per_sample = dim * 4 * 2
        return min(n_samples, int(usable_ram / bytes_per_sample))
```

#### 1.3 æ¢å¤å¹¶å¢å¼ºè¿”å›å€¼åŠŸèƒ½
```python
@operator_cache
def __call__(
    self,
    col_name: str,
    ncentroids: int,
    return_scores: bool = False,
    return_centroids: bool = False,
    return_inertia: bool = False,
    niter: int = 20,
    verbose: bool = False,
    prefer_gpu: bool = False,
) -> pd.DataFrame | tuple[pd.DataFrame, dict]:
    """
    è¿”å›å€¼:
    - å¦‚æœä»…è¿”å›DataFrame: åŒ…å«cluster_idåˆ—
    - å¦‚æœè¯·æ±‚é¢å¤–ä¿¡æ¯: (DataFrame, info_dict)
      info_dictå¯åŒ…å«: scores, centroids, inertia, silhouette_score
    """
```

#### 1.4 å‘é‡ç¼“å­˜ç­–ç•¥
```python
class VectorCache:
    """å‘é‡ç¼“å­˜ç®¡ç†å™¨"""
    def __init__(self, max_cache_size_gb=2):
        self._cache = {}
        self._max_size = max_cache_size_gb * 1024**3
        self._current_size = 0
    
    def get(self, key):
        return self._cache.get(key)
    
    def put(self, key, vectors):
        vector_size = vectors.nbytes
        if self._current_size + vector_size > self._max_size:
            self._evict_lru()
        self._cache[key] = vectors
        self._current_size += vector_size
```

### Phase 2: GPUåŠ é€Ÿä¼˜åŒ– (ä¸­ä¼˜å…ˆçº§)

#### 2.1 ç«¯åˆ°ç«¯GPUæµæ°´çº¿
```python
def _gpu_pipeline_cluster(df, col_name, ncentroids, ...):
    """å®Œæ•´GPUæµæ°´çº¿: å‘é‡åŠ è½½ -> GPUä¼ è¾“ -> K-means -> ç»“æœè¿”å›"""
    # 1. ä½¿ç”¨GPUå‹å¥½çš„å‘é‡æ ¼å¼(torch tensor)
    vectors = vs.get_vectors_from_index(col_index_dir, ids, return_tensor=True)
    
    # 2. é¿å…CPU-GPUå¾€è¿”
    if not vectors.is_cuda:
        vectors = vectors.cuda()
    
    # 3. GPU K-means
    assignments, scores, centroids = gpu_kmeans(vectors, ncentroids, ...)
    
    # 4. ä»…ä¼ è¾“æœ€ç»ˆç»“æœå›CPU
    return assignments.cpu().numpy()
```

#### 2.2 å¤šGPUæ”¯æŒ
```python
def _multi_gpu_cluster(vectors, ncentroids, gpu_ids=[0, 1]):
    """åˆ©ç”¨å¤šGPUå¹¶è¡Œèšç±»"""
    n_samples = len(vectors)
    chunk_size = n_samples // len(gpu_ids)
    
    # åˆ†é…æ•°æ®åˆ°ä¸åŒGPU
    # ä½¿ç”¨æ•°æ®å¹¶è¡ŒK-means
```

### Phase 3: ç”¨æˆ·ä½“éªŒä¼˜åŒ– (ä½ä¼˜å…ˆçº§)

#### 3.1 è¿›åº¦æ¡æ”¯æŒ
```python
from tqdm import tqdm

def __call__(self, ..., show_progress=False):
    if show_progress:
        pbar = tqdm(total=niter, desc="Clustering")
        # ... åœ¨è¿­ä»£ä¸­æ›´æ–°è¿›åº¦æ¡
```

#### 3.2 èšç±»è´¨é‡è¯„ä¼°
```python
def _evaluate_clustering(vectors, assignments, centroids):
    """è®¡ç®—èšç±»è´¨é‡æŒ‡æ ‡"""
    from sklearn.metrics import silhouette_score, calinski_harabasz_score
    
    return {
        'silhouette_score': silhouette_score(vectors, assignments),
        'calinski_harabasz_score': calinski_harabasz_score(vectors, assignments),
        'inertia': _compute_inertia(vectors, assignments, centroids)
    }
```

## ğŸ“ˆ é¢„æœŸæ€§èƒ½æå‡

| æ•°æ®è§„æ¨¡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡å€æ•° |
|---------|--------|--------|---------|
| 10K     | 2s     | 0.5s   | 4x      |
| 100K    | 45s    | 8s     | 5.6x    |
| 1M      | OOM    | 120s   | âˆâ†’å¯è¡Œ  |
| 10M     | N/A    | 25min  | æ–°æ”¯æŒ  |

**GPUåŠ é€Ÿ (ç›¸æ¯”CPUä¼˜åŒ–ç‰ˆæœ¬):**
- å°æ•°æ®é›†(10K): ~1.5x (GPUåˆå§‹åŒ–å¼€é”€)
- ä¸­æ•°æ®é›†(100K): ~3-4x
- å¤§æ•°æ®é›†(1M+): ~5-8x

## ğŸ”„ å®æ–½è®¡åˆ’

### Sprint 1 (Day 1-2): æ ¸å¿ƒä¼˜åŒ–
- [ ] å®ç°å‘é‡æ‰¹é‡è·å–
- [ ] æ·»åŠ è‡ªé€‚åº”æ‰¹å¤„ç†
- [ ] æ¢å¤return_scores/return_centroidsåŠŸèƒ½
- [ ] æ·»åŠ å‘é‡ç¼“å­˜

### Sprint 2 (Day 3-4): GPUä¼˜åŒ–
- [ ] ç«¯åˆ°ç«¯GPUæµæ°´çº¿
- [ ] ä¼˜åŒ–CPU-GPUæ•°æ®ä¼ è¾“
- [ ] æ”¹è¿›GPUå†…å­˜ç®¡ç†

### Sprint 3 (Day 5): å¢å¼ºåŠŸèƒ½
- [ ] æ·»åŠ è¿›åº¦æ¡
- [ ] èšç±»è´¨é‡è¯„ä¼°
- [ ] å®Œå–„é”™è¯¯å¤„ç†
- [ ] ç¼–å†™æ€§èƒ½åŸºå‡†æµ‹è¯•

### Sprint 4 (Day 6): æµ‹è¯•ä¸æ–‡æ¡£
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] æ›´æ–°æ–‡æ¡£å’Œç¤ºä¾‹
- [ ] ä»£ç å®¡æŸ¥

## ğŸ§ª æ€§èƒ½æµ‹è¯•è®¡åˆ’

```python
# benchmark_sem_cluster_by.py
def benchmark_clustering():
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    dataset_sizes = [1000, 10000, 100000, 1000000]
    
    for size in dataset_sizes:
        df = generate_test_df(size)
        
        # CPU baseline
        cpu_time = measure_time(df.sem_cluster_by(..., prefer_gpu=False))
        
        # GPU accelerated
        gpu_time = measure_time(df.sem_cluster_by(..., prefer_gpu=True))
        
        # è®°å½•å†…å­˜ä½¿ç”¨ã€ååé‡ç­‰æŒ‡æ ‡
```

## ğŸ’¡ æœªæ¥æ”¹è¿›æ–¹å‘

1. **å¢é‡èšç±»**: æ”¯æŒåŠ¨æ€æ·»åŠ æ–°æ•°æ®ç‚¹æ— éœ€é‡æ–°èšç±»
2. **åœ¨çº¿èšç±»**: æµå¼æ•°æ®èšç±»
3. **å±‚æ¬¡èšç±»**: æ”¯æŒHDBSCANç­‰é«˜çº§ç®—æ³•
4. **åˆ†å¸ƒå¼èšç±»**: æ”¯æŒSpark/Daskåˆ†å¸ƒå¼è®¡ç®—
5. **è‡ªåŠ¨è¶…å‚è°ƒä¼˜**: è‡ªåŠ¨ç¡®å®šæœ€ä¼˜èšç±»æ•°

## ğŸ“š å‚è€ƒèµ„æ–™

- [FAISS Wiki: Faster K-means](https://github.com/facebookresearch/faiss/wiki/Faster-search)
- [Efficient K-means on GPU](https://arxiv.org/abs/1702.07800)
- [Mini-batch K-means](https://scikit-learn.org/stable/modules/clustering.html#mini-batch-kmeans)

